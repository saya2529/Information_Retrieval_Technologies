{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import string\n",
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "# Function to read ground_truth.txt file\n",
    "def read_ground_truth(file_path):\n",
    "    ground_truth = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            # To avoid commented part of file\n",
    "            if line and not line.startswith('#'):\n",
    "                term, ids = line.split(' - ')\n",
    "                ground_truth[term] = [int(id) for id in ids.split(',')]\n",
    "    return ground_truth\n",
    "\n",
    "\n",
    "# Function to find the starting point of fables line number and skip introductory and index part\n",
    "def find_line_number(file_name, target_string):\n",
    "    line_number = 0\n",
    "    blank_lines_count = 0\n",
    "    with open(file_name, 'r') as file:\n",
    "        for line in file:\n",
    "            line_number += 1\n",
    "            if line.strip() == '':\n",
    "                blank_lines_count += 1\n",
    "            else:\n",
    "                if blank_lines_count == 2 and target_string in line:\n",
    "                    return line_number\n",
    "                blank_lines_count = 0\n",
    "    return -1\n",
    "\n",
    "\n",
    "# Function to extract fables\n",
    "def extract_fables(file_name):\n",
    "    collection_folder = 'collection_original'\n",
    "    if not os.path.exists(collection_folder):\n",
    "        os.makedirs(collection_folder)\n",
    "    # Call to the function find_line_number\n",
    "    linenum = find_line_number(file_name, \"Aesop's Fables\")\n",
    "    start_pattern = r\"Aesop's Fables\"  # Actual fable text starts from \"Aesop's Fables\"\n",
    "    start_index = linenum + 3  # +3 added because the actual lines are after 3 blank lines\n",
    "\n",
    "    with open(file_name, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    fables_content = ''.join(lines[start_index - 1:]).strip()\n",
    "    separated_fables = re.split(r'\\n\\n\\n', fables_content.strip())\n",
    "    fables = [fable.strip() for fable in separated_fables]\n",
    "\n",
    "    # Lists to store title and texts separately\n",
    "    titles = []\n",
    "    texts = []\n",
    "\n",
    "    # Loop to enumerate title and text\n",
    "    for j, fable in enumerate(fables, start=1):\n",
    "        lines = fable.split(\"\\n\")\n",
    "        # If-else case because in fable title and text are stored alternately\n",
    "        if j % 2 == 1:\n",
    "            title = lines[0].strip()\n",
    "            titles.append(title)\n",
    "        else:\n",
    "            text = '\\n'.join(lines[0:]).strip()\n",
    "            texts.append(text)\n",
    "\n",
    "    for i, (title, text) in enumerate(zip(titles, texts), start=1):\n",
    "        fable_number = str(i).zfill(2)\n",
    "        file_name = (\n",
    "            fable_number\n",
    "            + \"_\"\n",
    "            + re.sub(r'[_\\s]+', '_', title.lower()).strip(\",\\'\")\n",
    "            + '.txt'\n",
    "        )\n",
    "\n",
    "        with open(os.path.join(collection_folder, file_name), 'w') as fable_file:\n",
    "            fable_file.write(text)\n",
    "\n",
    "    print(\"Fables extracted successfully.\")\n",
    "\n",
    "    # Preprocess the extracted documents\n",
    "    source_folder = 'collection_original'\n",
    "    target_folder = 'collection_no_stopwords'\n",
    "    # Call this function here to preprocess documents and avoid the use of additional command\n",
    "    preprocess_documents(source_folder, target_folder)\n",
    "\n",
    "\n",
    "# ------------------------------------------Stopword removal------------------------------------------------------------\n",
    "# Function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    with open('englishST.txt', 'r') as stopwords_file:\n",
    "        stopwords = stopwords_file.read().splitlines()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = text.replace('\\n', ' ')\n",
    "    words = text.lower().split()\n",
    "    filtered_words = [word for word in words if word not in stopwords]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "\n",
    "# ------------------------------------------Stemming using porter algorithm------------------------------------------------------------\n",
    "# Function to apply stemming using the Porter algorithm using porter.txt file\n",
    "def apply_stemming(word):\n",
    "    def is_consonant(char):\n",
    "        vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "        return char.isalpha() and char.lower() not in vowels\n",
    "\n",
    "    # Step 1a: Apply rules for plurals\n",
    "    if word.endswith(\"sses\"):\n",
    "        word = word[:-2]\n",
    "    elif word.endswith(\"ies\"):\n",
    "        word = word[:-2]\n",
    "    elif word.endswith(\"s\") and not word.endswith(\"ss\"):\n",
    "        word = word[:-1]\n",
    "\n",
    "    # Step 1b: Apply rules for specific endings\n",
    "    if word.endswith(\"eed\"):\n",
    "        if len(word) > 4:\n",
    "            word = word[:-1]\n",
    "    elif word.endswith(\"ed\"):\n",
    "        if \"a\" in word[:-2] or \"e\" in word[:-2] or \"i\" in word[:-2] or \"o\" in word[:-2] or \"u\" in word[:-2]:\n",
    "            word = word[:-2]\n",
    "            if word.endswith(\"at\") or word.endswith(\"bl\") or word.endswith(\"iz\"):\n",
    "                word += \"e\"\n",
    "            elif (word[-1] == word[-2]) and (word[-1] not in [\"l\", \"s\", \"z\"]):\n",
    "                word = word[:-1]\n",
    "        else:\n",
    "            if len(word) > 4:\n",
    "                word = word[:-2]\n",
    "    elif word.endswith(\"ing\"):\n",
    "        if \"a\" in word[:-3] or \"e\" in word[:-3] or \"i\" in word[:-3] or \"o\" in word[:-3] or \"u\" in word[:-3]:\n",
    "            word = word[:-3]\n",
    "            if word.endswith(\"at\") or word.endswith(\"bl\") or word.endswith(\"iz\"):\n",
    "                word += \"e\"\n",
    "            elif (word[-1] == word[-2]) and (word[-1] not in [\"l\", \"s\", \"z\"]):\n",
    "                word = word[:-1]\n",
    "        else:\n",
    "            if len(word) > 5:\n",
    "                word = word[:-3]\n",
    "\n",
    "    # Step 1c: Apply rule for \"y\" endings\n",
    "    if word.endswith(\"y\") and len(word) > 2:\n",
    "        if word[-2] not in [\"a\", \"e\", \"i\", \"o\", \"u\"]:\n",
    "            word = word[:-1] + \"i\"\n",
    "\n",
    "    # Step 2: Apply rules for specific endings\n",
    "    if word.endswith(\"ational\"):\n",
    "        if len(word) > 8:\n",
    "            word = word[:-5] + \"e\"\n",
    "    elif word.endswith(\"tional\"):\n",
    "        if len(word) > 7:\n",
    "            word = word[:-2]\n",
    "    elif word.endswith(\"enci\"):\n",
    "        if len(word) > 4:\n",
    "            word = word[:-1] + \"e\"\n",
    "    elif word.endswith(\"anci\"):\n",
    "        if len(word) > 4:\n",
    "            word = word[:-1] + \"e\"\n",
    "    elif word.endswith(\"izer\"):\n",
    "        if len(word) > 5:\n",
    "            word = word[:-1]\n",
    "    elif word.endswith(\"abli\"):\n",
    "        if len(word) > 4:\n",
    "            word = word[:-1] + \"e\"\n",
    "    elif word.endswith(\"alli\"):\n",
    "        if len(word) > 4:\n",
    "            word = word[:-2]\n",
    "   ```python\n",
    "    elif word.endswith(\"entli\"):\n",
    "        if len(word) > 5:\n",
    "            word = word[:-2]\n",
    "    elif word.endswith(\"eli\"):\n",
    "        if len(word) > 3:\n",
    "            word = word[:-2]\n",
    "    elif word.endswith(\"ousli\"):\n",
    "        if len(word) > 5:\n",
    "            word = word[:-2]\n",
    "    elif word.endswith(\"ization\"):\n",
    "        if len(word) > 7:\n",
    "            word = word[:-5] + \"e\"\n",
    "    elif word.endswith(\"ation\"):\n",
    "        if len(word) > 5:\n",
    "            word = word[:-3] + \"e\"\n",
    "    elif word.endswith(\"ator\"):\n",
    "        if len(word) > 4:\n",
    "            word = word[:-2]\n",
    "    elif word.endswith(\"alism\"):\n",
    "        if len(word) > 5:\n",
    "            word = word[:-3]\n",
    "    elif word.endswith(\"iveness\"):\n",
    "        if len(word) > 7:\n",
    "            word = word[:-4]\n",
    "    elif word.endswith(\"fulness\"):\n",
    "        if len(word) > 7:\n",
    "            word = word[:-4]\n",
    "    elif word.endswith(\"ousness\"):\n",
    "        if len(word) > 7:\n",
    "            word = word[:-4]\n",
    "    elif word.endswith(\"aliti\"):\n",
    "        if len(word) > 4:\n",
    "            word = word[:-3]\n",
    "    elif word.endswith(\"iviti\"):\n",
    "        if len(word) > 4:\n",
    "            word = word[:-3] + \"e\"\n",
    "    elif word.endswith(\"biliti\"):\n",
    "        if len(word) > 6:\n",
    "            word = word[:-5] + \"le\"\n",
    "\n",
    "    # Step 3: Apply rules for specific endings\n",
    "    if word.endswith(\"icate\"):\n",
    "        if len(word) > 5:\n",
    "            word = word[:-3]\n",
    "    elif word.endswith(\"ative\"):\n",
    "        if len(word) > 5:\n",
    "            word = word[:-5]\n",
    "    elif word.endswith(\"alize\"):\n",
    "        if len(word) > 5:\n",
    "            word = word[:-3]\n",
    "    elif word.endswith(\"iciti\"):\n",
    "        if len(word) > 5:\n",
    "            word = word[:-3]\n",
    "    elif word.endswith(\"ical\"):\n",
    "        if len(word) > 4:\n",
    "            word = word[:-2]\n",
    "    elif word.endswith(\"ful\"):\n",
    "        if len(word) > 3:\n",
    "            word = word[:-3]\n",
    "    elif word.endswith(\"ness\"):\n",
    "        if len(word) > 4:\n",
    "            word = word[:-4]\n",
    "\n",
    "    # Step 4: Apply rules for specific endings\n",
    "    if word.endswith(\"al\"):\n",
    "        if len(word) > 3:\n",
    "            word = word[:-2]\n",
    "    elif word.endswith(\"ance\"):\n",
    "        if len(word) > 4:\n",
    "            word = word[:-4]\n",
    "    elif word.endswith(\"ence\"):\n",
    "        if len(word) > 4:\n",
    "            word = word[:-4]\n",
    "    elif word.endswith(\"er\"):\n",
    "        if len(word) > 2:\n",
    "            word = word[:-2]\n",
    "    elif word.endswith(\"ic\"):\n",
    "        if len(word) > 2:\n",
    "            word = word[:-2]\n",
    "    elif word.endswith(\"able\"):\n",
    "        if len(word) > 4:\n",
    "            word = word[:-4]\n",
    "    elif word.endswith(\"ible\"):\n",
    "        if len(word) > 4:\n",
    "            word = word[:-4]\n",
    "    elif word.endswith(\"ant\"):\n",
    "        if len(word) > 3:\n",
    "            word = word[:-3]\n",
    "    elif word.endswith(\"ement\"):\n",
    "        if len(word) > 5:\n",
    "            word = word[:-5]\n",
    "    elif word.endswith(\"ment\"):\n",
    "        if len(word) > 3:\n",
    "            word = word[:-4]\n",
    "    elif word.endswith(\"ent\"):\n",
    "        if len(word) > 2:\n",
    "            word = word[:-3]\n",
    "    elif word.endswith(\"ion\"):\n",
    "        if len(word) > 3 and word[-4] in [\"s\", \"t\"]:\n",
    "            word = word[:-3]\n",
    "    elif word.endswith(\"ou\"):\n",
    "        if len(word) > 2:\n",
    "            word = word[:-2]\n",
    "    elif word.endswith(\"ism\"):\n",
    "        if len(word) > 3:\n",
    "            word = word[:-3]\n",
    "    elif word.endswith(\"ate\"):\n",
    "        if len(word) > 3:\n",
    "            word = word[:-3]\n",
    "    elif word.endswith(\"iti\"):\n",
    "        if len(word) > 3:\n",
    "            word = word[:-3]\n",
    "    elif word.endswith(\"ous\"):\n",
    "        if len(word) > 3:\n",
    "            word = word[:-3]\n",
    "    elif word.endswith(\"ive\"):\n",
    "        if len(word) > 3:\n",
    "            word = word[:-3]\n",
    "    elif word.endswith(\"ize\"):\n",
    "        if len(word) > 3:\n",
    "            word = word[:-3]\n",
    "\n",
    "    # Step 5a: Apply rule for \"e\" endings\n",
    "    if word.endswith(\"e\") and len(word) > 1:\n",
    "        if len(word) > 2 or (len(word) == 2 and not is_consonant(word[-2]) and is_consonant(word[-3])):\n",
    "            word = word[:-1]\n",
    "\n",
    "    # Step 5b: Apply rule for \"ll\" endings\n",
    "    if word.endswith(\"ll\") and len(word) > 2:\n",
    "        word = word```python\n",
    "        word[:-1]\n",
    "\n",
    "    return word\n",
    "\n",
    "\n",
    "# Function to preprocess the documents\n",
    "def preprocess_documents(source_folder, target_folder):\n",
    "    if not os.path.exists(target_folder):\n",
    "        os.makedirs(target_folder)\n",
    "    for file_name in os.listdir(source_folder):\n",
    "        with open(os.path.join(source_folder, file_name), 'r') as file:\n",
    "            content = file.read()\n",
    "        if '--stemming' in sys.argv:\n",
    "            content = apply_stemming(content)\n",
    "        else:\n",
    "            content = remove_stopwords(content)\n",
    "        target_file_name = os.path.join(target_folder, file_name)\n",
    "        with open(target_file_name, 'w') as file:\n",
    "            file.write(content)\n",
    "\n",
    "    print(\"Documents preprocessed successfully.\")\n",
    "\n",
    "\n",
    "# ------------------------------------------Search------------------------------------------------------------\n",
    "\n",
    "# Function for linear search\n",
    "def linear_search(query, model, folder, apply_stemming_flag, ground_truth):\n",
    "    if apply_stemming_flag:\n",
    "        query = apply_stemming(query)\n",
    "    else:\n",
    "        query = remove_stopwords(query)\n",
    "\n",
    "    print(f\"Model: {model}, Query: {query}\")\n",
    "    print(\"Search Results:\")\n",
    "    results = []\n",
    "    start_time = time.time()\n",
    "    for file_name in os.listdir(folder):\n",
    "        with open(os.path.join(folder, file_name), 'r') as file:\n",
    "            content = file.read()\n",
    "\n",
    "        if query.lower() in content.lower():\n",
    "            results.append(file_name)\n",
    "    end_time = time.time()\n",
    "    execution_time = (end_time - start_time) * 1000\n",
    "\n",
    "    relevant_docs = set()\n",
    "\n",
    "    for result in results:\n",
    "        doc_id = int(result.split('_')[0])\n",
    "        relevant_docs.add(doc_id)\n",
    "\n",
    "    precision = 0.0  # Initialize with default value\n",
    "    recall = 0.0  # Initialize with default value\n",
    "\n",
    "    if query in ground_truth:\n",
    "        relevant_docs_ground_truth = set(ground_truth[query])\n",
    "        true_positives = len(relevant_docs.intersection(relevant_docs_ground_truth))\n",
    "        retrieved_docs = len(relevant_docs)\n",
    "\n",
    "        if retrieved_docs > 0:\n",
    "            precision = true_positives / retrieved_docs\n",
    "\n",
    "        if len(relevant_docs_ground_truth) > 0:\n",
    "            recall = true_positives / len(relevant_docs_ground_truth)\n",
    "        precision_str = f\"P={precision:.2f}\"\n",
    "        recall_str = f\"R={recall:.2f}\"\n",
    "    else:\n",
    "        precision_str = \"P=?\"\n",
    "        recall_str = \"R=?\"\n",
    "\n",
    "    return results, execution_time, precision_str, recall_str\n",
    "\n",
    "\n",
    "# Function for inverted list search\n",
    "def inverted_list_search(query, model, folder, apply_stemming_flag, ground_truth):\n",
    "    if apply_stemming_flag:\n",
    "        query = apply_stemming(query)\n",
    "    else:\n",
    "        query = remove_stopwords(query)\n",
    "\n",
    "    print(f\"Model: {model}, Query: {query}\")\n",
    "    print(\"Search Results:\")\n",
    "\n",
    "    inverted_index = {}\n",
    "    start_time = time.time()\n",
    "    for file_name in os.listdir(folder):\n",
    "        with open(os.path.join(folder, file_name), 'r') as file:\n",
    "            content = file.read()\n",
    "        words = content.lower().split()\n",
    "        translator = str.maketrans(\"\", \"\", string.punctuation)  # Translator to remove punctuation marks\n",
    "        for word in words:\n",
    "            word = word.translate(translator)  # Remove punctuation marks from the word\n",
    "            if word:\n",
    "                if word not in inverted_index:\n",
    "                    inverted_index[word] = []\n",
    "                inverted_index[word].append(file_name)\n",
    "\n",
    "    # Process the query terms\n",
    "    results = None\n",
    "    operators = ['&', '|', '-']\n",
    "    query_terms = []\n",
    "    query_operator = None\n",
    "\n",
    "    for operator in operators:\n",
    "        if operator in query:\n",
    "            query_terms = query.split(operator)\n",
    "            query_operator = operator\n",
    "            break\n",
    "\n",
    "    start_time = time.time()\n",
    "    # for conjunction\n",
    "    if query_operator == '&':\n",
    "        term1 = query_terms[0].strip()\n",
    "        term2 = query_terms[1].strip()\n",
    "        results_term1 = set(inverted_index.get(term1, []))\n",
    "        results_term2 = set(inverted_index.get(term2, []))\n",
    "        results = list(results_term1.intersection(results_term2))\n",
    "    # for disjunction\n",
    "    elif query_operator == '|':\n",
    "        term1 = query_terms[0].strip()\n",
    "        term2 = query_terms[1].strip()\n",
    "        results = list(set(inverted_index.get(term1, [])) | set(inverted_index.get(term2, [])))\n",
    "    # for negation\n",
    "    elif query_operator == '-':\n",
    "        negation_term = query_terms[0].strip()[1:]\n",
    "        results = list(set(os.listdir(folder)) - set(inverted_index.get(negation_term, [])))\n",
    "\n",
    "    precision = recall = 0.0\n",
    "    relevant_docs = set()\n",
    "\n",
    "    for result in results:\n",
    "        doc_id = int(result.split('_')[0])\n",
    "        relevant_docs.add(doc_id)\n",
    "\n",
    "    if query_terms:\n",
    "        relevant_docs_ground_truth = set()\n",
    "        for term in query_terms:\n",
    "            if term in ground_truth:\n",
    "                relevant_docs_ground_truth.update(ground_truth[term])\n",
    "\n",
    "        true_positives = len(relevant_docs.intersection(relevant_docs_ground_truth))\n",
    "        retrieved_docs = len(relevant_docs)\n",
    "\n",
    "        if retrieved_docs > 0:\n",
    "            precision = true_positives / retrieved_docs\n",
    "\n",
    "        if```python\n",
    "        len(relevant_docs_ground_truth) > 0:\n",
    "            recall = true_positives / len(relevant_docs_ground_truth)\n",
    "\n",
    "        precision_str = f\"P={precision:.2f}\"\n",
    "        recall_str = f\"R={recall:.2f}\"\n",
    "    else:\n",
    "        precision_str = \"P=?\"\n",
    "        recall_str = \"R=?\"\n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = (end_time - start_time) * 1000\n",
    "\n",
    "    return results, execution_time, precision_str, recall_str\n",
    "\n",
    "\n",
    "# ------------------------------------------Main code------------------------------------------------------------\n",
    "\n",
    "# Read the ground_truth.txt file\n",
    "ground_truth = read_ground_truth(\"ground_truth.txt\")\n",
    "\n",
    "# Extract fables from the given file\n",
    "file_name = \"aesop.txt\"\n",
    "extract_fables(file_name)\n",
    "\n",
    "# Define the model and folder paths\n",
    "models = [\"linear\", \"inverted\"]\n",
    "folders = [\"collection_no_stopwords\", \"collection_stemming\"]\n",
    "\n",
    "# Query examples\n",
    "queries = [\"fox\", \"lion\", \"rabbit\", \"fox & lion\", \"fox | lion\", \"-fox\", \"-lion\", \"fox & -lion\", \"fox | -lion\"]\n",
    "\n",
    "# Perform search for each model and folder combination\n",
    "for model in models:\n",
    "    for folder in folders:\n",
    "        print(f\"\\n==============================\\nModel: {model}, Folder: {folder}\\n==============================\")\n",
    "        if model == \"linear\":\n",
    "            for query in queries:\n",
    "                results, execution_time, precision, recall = linear_search(query, model, folder, folder == \"collection_stemming\", ground_truth)\n",
    "                print(f\"Query: {query}\")\n",
    "                print(f\"Results: {results}\")\n",
    "                print(f\"Execution Time: {execution_time:.2f} ms\")\n",
    "                print(f\"Precision: {precision}\")\n",
    "                print(f\"Recall: {recall}\")\n",
    "                print()\n",
    "        elif model == \"inverted\":\n",
    "            for query in queries:\n",
    "                results, execution_time, precision, recall = inverted_list_search(query, model, folder, folder == \"collection_stemming\", ground_truth)\n",
    "                print(f\"Query: {query}\")\n",
    "                print(f\"Results: {results}\")\n",
    "                print(f\"Execution Time: {execution_time:.2f} ms\")\n",
    "                print(f\"Precision: {precision}\")\n",
    "                print(f\"Recall: {recall}\")\n",
    "                print()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
